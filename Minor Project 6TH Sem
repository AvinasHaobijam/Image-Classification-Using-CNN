path = 'AnimalDataset/AnimalDataset/raw-img'

import os
class_names = sorted(os.listdir(path))
n_classes = len(class_names)
print(f"Class Names: \n{class_names}")
print(f"Total Number of Classes : {n_classes}")

class_dis = [len(os.listdir(path + f"/{name}")) for name in class_names]
print(f"Class Distribution : \n{class_dis}")

pip install --upgrade plotly

import plotly.express as px
fig = px.pie(names=class_names, values=class_dis, width=600)
fig.update_layout({"title":{'text':"Class Distribution","x":0.5}})
fig.show()
print(fig)

from keras.preprocessing.image import ImageDataGenerator
import  matplotlib.pyplot as plt
import numpy as np

generator = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=20,
    validation_split=0.2
)

train_ds = generator.flow_from_directory(
    path,
    target_size=(256,256),
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    subset='training')

valid_ds = generator.flow_from_directory(
    path,
    target_size=(256,256),
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    subset='validation')

def show_image(img, title=None):
    '''The function takes in a Image and plots it'''
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def get_random_data(data):
    '''The function gets random image and label from the input data'''
    images, labels = data
    id = np.random.randint(len(images))
    image, label = images[id], labels[id]
    return image, label

plt.figure(figsize=(20,20))
i=1
for images, labels in iter(train_ds):

    # Get Random Image and label
    image, label = get_random_data([images, labels])

    # Plot it
    plt.subplot(5,5,i)
    show_image(image, title=f"Class : {class_names[int(label)]}")

    # Make sure to end the Loop
    i+=1
    if i>=26: break


plt.tight_layout()
plt.show()

from tensorflow.keras.applications import ResNet152V2
from keras import Sequential
from keras.layers import Dense, GlobalAvgPool2D as GAP, Dropout

'''
include_top: This parameter specifies whether or not to include the fully-connected layer at the top of the network.
If include_top=True, the model will include the fully-connected layer, which is used for classification.
If include_top=False, the model will not include the fully-connected layer, which means that you will need to add your own fully-connected layer to the top of the model.
The default value for include_top is True.
'''
base_model = ResNet152V2(include_top=False, input_shape=(256,256,3), weights='imagenet')
base_model.trainable = False # Freeze the Weights

# Model
name = "ResNet152V2"
resnet152V2 = Sequential([
    base_model,
    GAP(),
    Dense(256, activation='relu'),
    Dropout(0.2),
    Dense(n_classes, activation='softmax')
], name=name)

resnet152V2.compile(
   loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
    )

resnet152V2.summary()

import tqdm

history = resnet152V2.fit(
        train_ds,
        validation_data=valid_ds,
        epochs=5,  # Train for 1 epoch at a time
        callbacks=cbs,
    )

from tensorflow.keras.models import load_mode

model  = load_model("ResNet152V2.h5")

visualkeras.layered_view(model).show()                        # display using your system viewer
visualkeras.layered_view(model, to_file='output.png')         # write to disk
visualkeras.layered_view(model, to_file='output.png').show()  # write and show
visualkeras.layered_view(model)

import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions
from tensorflow.keras.models import load_model

image_path = 'TestImages/colorful-butterfly-pictures.jpg'

# load the image from target path and resize it to the target size
img = image.load_img(image_path, target_size=(256, 256))
# convert the image to numpy array
img_array = image.img_to_array(img)
print(f'Image Shape before expanding dimensions: {img_array.shape}')
# adds an extra dimension to the array at specified axis, usually done to convert single image to batch of image
img_array = np.expand_dims(img_array, axis=0)
print(f'Image Shape after expanding dimensions: {img_array.shape}')
# preprocess the input according to theresnet_
img_array = preprocess_input(img_array)

prediction = model.predict(img_array)
print(prediction)
# print(prediction.shape)

class_labels = {0: 'Butterfly', 1: 'Cat', 2: 'Cow', 3: 'Dog', 4: 'Hen'}

# Get the top predicted class index
predicted_class_index = np.argmax(prediction)

# Map the class index to the corresponding label
predicted_class_label = class_labels[predicted_class_index]

# Print the predicted class label
print(f"Predicted Class: {predicted_class_label}")# Plot training and validation loss
plt.plot(history.['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot training and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

predictions = model.predict(test_ds)
prediction = np.argmax(predictions, axis=1)
print(prediction.shape)
print(prediction[7])

from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(true_labels, prediction)
conf_matrix

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

model = tf.keras.models.load_model('ResNet152V2.h5')

model.summary()

custom_objects = {'BatchNormalization': tf.keras.layers.BatchNormalization}
model = tf.keras.models.load_model('ResNet152V2.h5', compile=False, custom_objects=custom_objects)

model = tf.keras.models.load_model('ResNet152V2.h5')

img_path = "TestAnimalDataset/TestAnimalDataset/Butterfly/butterfly.jpeg"

img = image.load_img(image_path, target_size=(256, 256))
# convert the image to numpy array
img_array = image.img_to_array(img)
print(f'Image Shape before expanding dimensions: {img_array.shape}')
# adds an extra dimension to the array at specified axis, usually done to convert single image to batch of image
img_array = np.expand_dims(img_array, axis=0)
print(f'Image Shape after expanding dimensions: {img_array.shape}')
# preprocess the input according to theresnet_
img_array = preprocess_input(img_array)

model.predict(img_array )
model.summary()
print(tf.__version__)
